{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 6, 29, 3, 47, 31, 589750)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Head Hunter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_head_hunter(page, position, vacancy_hh = []):\n",
    "    \"\"\"\n",
    "    В этой функии мы парсим страницы сайта hh\n",
    "    \n",
    "    page: передаем список с номерами страниц и после проверки будем его переводить во множество, \n",
    "          чтобы исключить повторения\n",
    "          \n",
    "          \n",
    "    position: Передаем должность, по которой будем собирать данные  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    main_link = 'https://hh.ru/'\n",
    "\n",
    "\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "                            AppleWebKit/537.36 (KHTML, like Gecko)\\\n",
    "                            Chrome/83.0.4103.116 Safari/537.36'}\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Список для хранения данных по должности \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Перебираем все страницы \n",
    "\n",
    "        \n",
    "    params = {'text':position,\n",
    "                 'area':1,\n",
    "                  'L_save_area':True,\n",
    "                 'clusters':True,\n",
    "                 'enable_snippets':True,\n",
    "                  'st':'searchVacancy',\n",
    "                 'fromSearch':True,\n",
    "                 'from':'suggest_post',\n",
    "                  'customDomain':1,\n",
    "                  'page':page-1\n",
    "                 }\n",
    "\n",
    "    html = requests.get(main_link + 'search/vacancy/' , headers = headers, params = params)\n",
    "\n",
    "    soup = bs(html.text,'html.parser')\n",
    "\n",
    "    vacancy_block = soup.find('div',{'class':'vacancy-serp'})\n",
    "\n",
    "    vacancy_list = vacancy_block.find_all('div',{'class':'vacancy-serp-item'})\n",
    "\n",
    "\n",
    "    for i in vacancy_list:\n",
    "        vacancy_dict = {}\n",
    "        vacancy_name = i.find('a',{'class':'bloko-link'}).getText()\n",
    "        vacancy_link = i.find('a',{'class':'bloko-link'})['href']\n",
    "        vacancy_salary = i.find('div',{'class':'vacancy-serp-item__sidebar'}).getText()\n",
    "        vacancy_employer = i.find('div',{'class':'vacancy-serp-item__meta-info'}).getText()\n",
    "        vacancy_city = i.find('span',{'class':'vacancy-serp-item__meta-info'}).getText().split(', ')\n",
    "        vacancy_date = i.find('span',{'class':'vacancy-serp-item__publication-date'}).getText()\n",
    "\n",
    "\n",
    "\n",
    "        currency = vacancy_salary[-4:] # выводим валюту\n",
    "        if not currency:\n",
    "            currency = np.nan\n",
    "        else:\n",
    "            vacancy_salary = vacancy_salary.replace(currency,'') # удаляем валюту\n",
    "\n",
    "\n",
    "        #Проверка метро, если указано метро. то мы его найдем при попощи проверки\n",
    "        # если его нет , то ставим NaN\n",
    "        if len(vacancy_city)>1:\n",
    "            vacancy_metro = vacancy_city[1]\n",
    "        else:\n",
    "            vacancy_metro  = np.nan\n",
    "\n",
    "\n",
    "        # Делаем разделение на минимальную и максимальную ЗП. \n",
    "        # Если где-то не указана сумма ЗП за то мы заполняем значением NaN\n",
    "        if '-' in vacancy_salary:\n",
    "\n",
    "            salaty_split = vacancy_salary.split('-')\n",
    "            salary_min = salaty_split[0].replace(' ','')\n",
    "            salary_max = salaty_split[1].replace(' ','')\n",
    "\n",
    "        elif 'от' in vacancy_salary:\n",
    "\n",
    "            salaty_rep = vacancy_salary.replace('от ','')\n",
    "            salary_min = salaty_rep\n",
    "            salary_max = np.nan\n",
    "\n",
    "        elif 'до' in vacancy_salary:\n",
    "\n",
    "            salaty_rep = vacancy_salary.replace('до ','')\n",
    "            salary_min = np.nan\n",
    "            salary_max = salaty_rep\n",
    "\n",
    "        else:\n",
    "            salary_min = np.nan\n",
    "            salary_max = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        vacancy_dict['vacancy_employer'] = vacancy_employer\n",
    "        vacancy_dict['vacancy_name'] = vacancy_name\n",
    "        vacancy_dict['salary_min'] = salary_min\n",
    "        vacancy_dict['salary_max'] = salary_max\n",
    "        vacancy_dict['currency'] = currency\n",
    "        vacancy_dict['vacancy_city'] = vacancy_city[0]\n",
    "        vacancy_dict['vacancy_date'] = vacancy_date\n",
    "        vacancy_dict['vacancy_link'] = vacancy_link[:vacancy_link.index('?')]\n",
    "\n",
    "\n",
    "        vacancy_hh.append(vacancy_dict)\n",
    "        \n",
    "        \n",
    "    return vacancy_hh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SuperJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_super_job(page, position,vacancy_sj = []): \n",
    "    \n",
    "    \"\"\"\n",
    "    В этой функии мы парсим страницы сайта SJ\n",
    "    \n",
    "    page: передаем множесво с номерами страниц, \n",
    "          чтобы не повторялимь значения и мы не собирали одинаковые данные\n",
    "          \n",
    "    position: Передаем должность, по которой будем собирать данные  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    main_link_sj = 'https://superjob.ru'\n",
    "\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "                            AppleWebKit/537.36 (KHTML, like Gecko)\\\n",
    "                            Chrome/83.0.4103.116 Safari/537.36'}\n",
    "    \n",
    "    \n",
    "        \n",
    "    params = {'keywords':position,\n",
    "                 'page': page}\n",
    "\n",
    "    html_sj = requests.get(main_link_sj+'/vacancy/search/', headers = headers, params = params)\n",
    "\n",
    "    soup = bs(html_sj.text,'html.parser')\n",
    "\n",
    "    vacancy_block = soup.find('div',{'class':'_1ID8B'})\n",
    "\n",
    "    vacancy_list = vacancy_block.find_all('div',{'class':'Fo44F'})\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    for i in vacancy_list:\n",
    "        vacancy_dict = {}\n",
    "\n",
    "        vacancy_name = i.find('div',{'class':'_3mfro'}).getText()\n",
    "        vacancy_link = i.find('a',{'class':'icMQ_'})['href']\n",
    "        vacancy_employer = i.find_all('a',{'class':'icMQ_'})[1].getText()\n",
    "        vacancy_salary = i.find_all('span',{'class':'_3mfro'})[0].getText()\n",
    "        vacancy_city = i.find_all('span',{'class':'_9fXTd'})[1].getText()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if 'По дого' in vacancy_salary:\n",
    "            currency = np.nan\n",
    "        else:\n",
    "            currency = vacancy_salary[-4:] # выводим валюту\n",
    "            vacancy_salary = vacancy_salary.replace(currency,'') # удаляем валюту   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if '—' in vacancy_salary:\n",
    "            salaty_split = vacancy_salary.split('—')\n",
    "            salary_min = salaty_split[0]\n",
    "            salary_max = salaty_split[1]\n",
    "        elif 'от\\xa0' in vacancy_salary:\n",
    "            salaty_rep = vacancy_salary.replace('от\\xa0','')\n",
    "            salary_min = salaty_rep\n",
    "            salary_max = np.nan\n",
    "        elif 'до\\xa0' in vacancy_salary:\n",
    "            salaty_rep = vacancy_salary.replace('до\\xa0','')\n",
    "            salary_min = np.nan\n",
    "            salary_max = salaty_rep\n",
    "        else:\n",
    "            salary_min = np.nan\n",
    "            salary_max = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        vacancy_date = vacancy_city.split(' • ')[0]\n",
    "        vacancy_metro = np.nan\n",
    "\n",
    "        if len(vacancy_city.split(' • ')) == 1:\n",
    "            vacancy_city = [np.nan]\n",
    "\n",
    "        elif len(vacancy_city.split(' • ')) == 2:\n",
    "            vacancy_city = vacancy_city.split(' • ')[1].split(', ')\n",
    "                \n",
    "\n",
    "        vacancy_dict['vacancy_employer'] = vacancy_employer\n",
    "        vacancy_dict['vacancy_name'] = vacancy_name\n",
    "        vacancy_dict['salary_min'] = salary_min\n",
    "        vacancy_dict['salary_max'] = salary_max\n",
    "        vacancy_dict['currency'] = currency\n",
    "        vacancy_dict['vacancy_city'] = vacancy_city[0]\n",
    "        vacancy_dict['vacancy_date'] = vacancy_date\n",
    "        vacancy_dict['vacancy_link'] = main_link_sj+vacancy_link\n",
    "\n",
    "\n",
    "\n",
    "        vacancy_sj.append(vacancy_dict)\n",
    "    \n",
    "    return vacancy_sj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Возможные страницы для поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_number_page_SJ(number, position):\n",
    "    \n",
    "    main_link_sj = 'https://superjob.ru'\n",
    "\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "                            AppleWebKit/537.36 (KHTML, like Gecko)\\\n",
    "                            Chrome/83.0.4103.116 Safari/537.36'}\n",
    "    vacancy_sj = []\n",
    "\n",
    "        \n",
    "    params = {'keywords':position}\n",
    "\n",
    "    html_sj = requests.get(main_link_sj+'/vacancy/search/', headers = headers, params = params)\n",
    "\n",
    "    soup = bs(html_sj.text,'html.parser')\n",
    "    \n",
    "    count_block = soup.find('div',{'class':'L1p51'})\n",
    "    \n",
    "    if count_block:\n",
    "\n",
    "        max_count_list = count_block.find_all('span',{'class':'_3IDf-'})[-2].getText()\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "    return np.arange(1,int(max_count_list)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_number_page_HH(number, position):\n",
    "    \n",
    "    main_link_hh = 'https://hh.ru/'\n",
    "\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "                            AppleWebKit/537.36 (KHTML, like Gecko)\\\n",
    "                            Chrome/83.0.4103.116 Safari/537.36'}\n",
    "\n",
    "\n",
    "\n",
    "    params = {'text':position,\n",
    "             'area':1,\n",
    "              'L_save_area':True,\n",
    "             'clusters':True,\n",
    "             'enable_snippets':True,\n",
    "              'st':'searchVacancy',\n",
    "             'fromSearch':True,\n",
    "             'from':'suggest_post',\n",
    "              'customDomain':1,\n",
    "              'page':number-1\n",
    "             }\n",
    "    \n",
    "    html = requests.get(main_link_hh + 'search/vacancy/' , headers = headers, params = params)\n",
    "\n",
    "    soup = bs(html.text,'html.parser')\n",
    "\n",
    "    count_block = soup.find('div',{'data-qa':'pager-block'})\n",
    "    \n",
    "    if count_block:\n",
    "        \n",
    "        max_count_list = count_block.find_all('a',{'class':'bloko-button'})[-2].getText()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "\n",
    "    return np.arange(1,int(max_count_list)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_set_all(value_1, value_2):\n",
    "    \n",
    "    \"\"\"\n",
    "        Функция сделана для преобразование и объединения DataSet \n",
    "        настройка индексов и преобразование зарплаты в тип int\n",
    "        Делаем переименование столбцов и добавляем сайт , откуда был собран материал \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_1 = pd.DataFrame(value_1)\n",
    "    \n",
    "    df_2 = pd.DataFrame(value_2)\n",
    "    \n",
    "    df = pd.concat((df_1, df_2))\n",
    "    \n",
    "    df['website'] = 'www.'+df['vacancy_link'].str.extract(\"(\\w+)\\.\")+'.ru'\n",
    "    \n",
    "    df = df.rename(columns = {'vacancy_employer':'Работодатель',\n",
    "         'vacancy_name':'Вакансия',\n",
    "         'salary_min':'Зарплата_от',\n",
    "         'salary_max':'Зарплата_до',\n",
    "         'vacancy_city':'Город',\n",
    "         'vacancy_date':'Дата_публикации',\n",
    "         'vacancy_link':'Ссылка_на_вакансию',\n",
    "          'website':'Сайт',\n",
    "            'currency':'Валюта'})\n",
    "    \n",
    "    df = df.reset_index().drop('index',axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.loc[df['Зарплата_от'].isnull(), 'Зарплата_от'] = '0'\n",
    "    df.loc[df['Зарплата_до'].isnull(), 'Зарплата_до'] = '0'\n",
    "    \n",
    "    df['Зарплата_от'] = df['Зарплата_от'].str.replace('\\xa0','').astype(int)\n",
    "    df['Зарплата_до'] = df['Зарплата_до'].str.replace('\\xa0','').astype(int)\n",
    "    \n",
    "    df.style.highlight_null(null_color='red')\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Должность "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Введите должность, напрмиер Аналитик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите должность: Аналитик\n"
     ]
    }
   ],
   "source": [
    "position = input('Введите должность: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбор данных c HeadHunter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pages_hh = max_number_page_HH(1,position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Страницы для поиска на hh.ru: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40]\n",
      "\n",
      "\n",
      "(Введите страницы через пробел или одну страницу)\n",
      "С каких страниц собираем данные? hh.ru: 1 2 3\n",
      "Оставшиеся страницы для парсинга: [ 4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27\n",
      " 28 29 30 31 32 33 34 35 36 37 38 39 40]\n",
      "Продолжить парсинг? y/n: n\n"
     ]
    }
   ],
   "source": [
    "print(f'Страницы для поиска на hh.ru: {my_pages_hh}\\n')\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    pages_hh = np.array(input('(Введите страницы через пробел или одну страницу)\\nС каких страниц собираем данные? hh.ru: ').split()).astype(int)\n",
    "    \n",
    "    for i in range(len(pages_hh)):\n",
    "        if pages_hh[i] == 0:\n",
    "            pages_hh[i] = 1\n",
    "    \n",
    "    \n",
    "    if pages_hh.size == 0:\n",
    "        continue\n",
    "    \n",
    "    count_false = 0\n",
    "\n",
    "    for number_page_hh in pages_hh:\n",
    "\n",
    "        if np.in1d(number_page_hh, my_pages_hh):\n",
    "\n",
    "            my_data_hh = parse_head_hunter(number_page_hh,position)\n",
    "\n",
    "            my_pages_hh = np.setdiff1d([my_pages_hh],number_page_hh)\n",
    "        else:\n",
    "            count_false+=1\n",
    "            \n",
    "    if count_false == pages_hh.size:\n",
    "        \n",
    "        print('Указаны страницы, которых нет или уже проверена')\n",
    "        print()\n",
    "        \n",
    "        no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        while (no_or_yes != 'y') and (no_or_yes !='n'):\n",
    "            \n",
    "            print('Не корректный ввод')\n",
    "            print()\n",
    "            \n",
    "            no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        if no_or_yes == 'y':\n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "            \n",
    "    print(f'Оставшиеся страницы для парсинга: {my_pages_hh}')\n",
    "    \n",
    "    if my_pages_hh.size != 0:\n",
    "        \n",
    "        no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        while (no_or_yes != 'y') and (no_or_yes !='n'):\n",
    "            \n",
    "            print('Не корректный ввод')\n",
    "            print()\n",
    "            \n",
    "            no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        if no_or_yes == 'y':\n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "    else:\n",
    "        \n",
    "        print('Страниц для парсинга не осталось')\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбор данных c SuperJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pages_sj = max_number_page_SJ(1,position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Страницы для парсинга на superjob.ru: [1 2 3 4]\n",
      "\n",
      "(Введите страницы через пробел или одну страницу)\n",
      "С каких страниц собираем данные? superjob.ru: 1\n",
      "Оставшиеся страницы для парсинга: [2 3 4]\n",
      "\n",
      "Продолжить парсинг? y/n: n\n"
     ]
    }
   ],
   "source": [
    "print(f'Страницы для парсинга на superjob.ru: {my_pages_sj}')\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    pages_sj = np.array(input('(Введите страницы через пробел или одну страницу)\\nС каких страниц собираем данные? superjob.ru: ').split()).astype(int)\n",
    "    \n",
    "    for i in range(len(pages_sj)):\n",
    "        if pages_sj[i] == 0:\n",
    "            pages_sj[i] = 1\n",
    "\n",
    "    \n",
    "    if pages_sj.size == 0:\n",
    "        continue\n",
    "    \n",
    "    count_false = 0\n",
    "\n",
    "    for number_page_sj in pages_sj:\n",
    "\n",
    "        if np.in1d(number_page_sj, my_pages_sj):\n",
    "\n",
    "            my_data_sj = parse_super_job(number_page_sj,position)\n",
    "\n",
    "            my_pages_sj = np.setdiff1d([my_pages_sj],number_page_sj)\n",
    "        else:\n",
    "            count_false+=1\n",
    "            \n",
    "    if count_false == pages_sj.size:\n",
    "        \n",
    "        print('Указаны страницы, которых нет или уже проверена Вот тутн')\n",
    "        print()\n",
    "        \n",
    "        no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        while (no_or_yes != 'y') and (no_or_yes !='n'):\n",
    "            \n",
    "            print('Не корректный ввод')\n",
    "            print()\n",
    "            \n",
    "            no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        if no_or_yes == 'y':\n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "            \n",
    "    print(f'Оставшиеся страницы для парсинга: {my_pages_sj}')\n",
    "    print()\n",
    "    \n",
    "    if my_pages_sj.size != 0:\n",
    "        \n",
    "        no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        while (no_or_yes != 'y') and (no_or_yes !='n'):\n",
    "            \n",
    "            print('Не корректный ввод')\n",
    "            print()\n",
    "            \n",
    "            no_or_yes = input('Продолжить парсинг? y/n: ')\n",
    "\n",
    "        if no_or_yes == 'y':\n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "    else:\n",
    "        \n",
    "        print('Страниц для парсинга не осталось, данные собраны')\n",
    "        print()\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = df_set_all(my_data_hh, my_data_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Сайт\n",
       "www.hh.ru          150\n",
       "www.superjob.ru     20\n",
       "Name: Ссылка_на_вакансию, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.groupby('Сайт')['Ссылка_на_вакансию'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Работодатель</th>\n",
       "      <th>Вакансия</th>\n",
       "      <th>Зарплата_от</th>\n",
       "      <th>Зарплата_до</th>\n",
       "      <th>Валюта</th>\n",
       "      <th>Город</th>\n",
       "      <th>Дата_публикации</th>\n",
       "      <th>Ссылка_на_вакансию</th>\n",
       "      <th>Сайт</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ООО Your Suit</td>\n",
       "      <td>Руководитель отдела продаж / Директор по продажам</td>\n",
       "      <td>130000</td>\n",
       "      <td>250000</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>28 июня</td>\n",
       "      <td>https://hh.ru/vacancy/37713537</td>\n",
       "      <td>www.hh.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alphaopen</td>\n",
       "      <td>Бизнес-аналитик программного решения</td>\n",
       "      <td>160000</td>\n",
       "      <td>220000</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>26 июня</td>\n",
       "      <td>https://hh.ru/vacancy/37694581</td>\n",
       "      <td>www.hh.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NodaSoft</td>\n",
       "      <td>MSK.IT.ANALIST</td>\n",
       "      <td>120000</td>\n",
       "      <td>0</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>28 июня</td>\n",
       "      <td>https://hh.ru/vacancy/37715080</td>\n",
       "      <td>www.hh.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ООО Банкирро</td>\n",
       "      <td>Ведущий менеджер по продажам</td>\n",
       "      <td>170000</td>\n",
       "      <td>210000</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>26 июня</td>\n",
       "      <td>https://hh.ru/vacancy/37229320</td>\n",
       "      <td>www.hh.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Банк ВТБ (ПАО)</td>\n",
       "      <td>Стажер ВТБ IT-Юниор (Аналитика, разработка, De...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Москва</td>\n",
       "      <td>28 июня</td>\n",
       "      <td>https://hh.ru/vacancy/37595281</td>\n",
       "      <td>www.hh.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>НИИОЗММ ДЗМ</td>\n",
       "      <td>Аналитик (визионер)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Москва</td>\n",
       "      <td>Вчера</td>\n",
       "      <td>https://superjob.ru/vakansii/analitik-32380682...</td>\n",
       "      <td>www.superjob.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Эвотор</td>\n",
       "      <td>Аналитик SQL (DMP)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Москва</td>\n",
       "      <td>Вчера</td>\n",
       "      <td>https://superjob.ru/vakansii/analitik-sql-3402...</td>\n",
       "      <td>www.superjob.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>АНО Радиоканал \"Вера, надежда, любовь\"</td>\n",
       "      <td>CRM-менеджер (Аналитик)</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>27 июня</td>\n",
       "      <td>https://superjob.ru/vakansii/crm-menedzher-339...</td>\n",
       "      <td>www.superjob.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Sandwichbar</td>\n",
       "      <td>Аналитик продаж</td>\n",
       "      <td>65000</td>\n",
       "      <td>80000</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>27 июня</td>\n",
       "      <td>https://superjob.ru/vakansii/analitik-prodazh-...</td>\n",
       "      <td>www.superjob.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>«Черкизово»</td>\n",
       "      <td>Аналитик по планированию продаж</td>\n",
       "      <td>0</td>\n",
       "      <td>120000</td>\n",
       "      <td>руб.</td>\n",
       "      <td>Москва</td>\n",
       "      <td>27 июня</td>\n",
       "      <td>https://superjob.ru/vakansii/analitik-po-plani...</td>\n",
       "      <td>www.superjob.ru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Работодатель  \\\n",
       "0                            ООО Your Suit    \n",
       "1                                Alphaopen    \n",
       "2                                 NodaSoft    \n",
       "3                             ООО Банкирро    \n",
       "4                           Банк ВТБ (ПАО)    \n",
       "..                                      ...   \n",
       "165                             НИИОЗММ ДЗМ   \n",
       "166                                  Эвотор   \n",
       "167  АНО Радиоканал \"Вера, надежда, любовь\"   \n",
       "168                             Sandwichbar   \n",
       "169                             «Черкизово»   \n",
       "\n",
       "                                              Вакансия  Зарплата_от  \\\n",
       "0    Руководитель отдела продаж / Директор по продажам       130000   \n",
       "1                 Бизнес-аналитик программного решения       160000   \n",
       "2                                       MSK.IT.ANALIST       120000   \n",
       "3                         Ведущий менеджер по продажам       170000   \n",
       "4    Стажер ВТБ IT-Юниор (Аналитика, разработка, De...            0   \n",
       "..                                                 ...          ...   \n",
       "165                                Аналитик (визионер)            0   \n",
       "166                                 Аналитик SQL (DMP)            0   \n",
       "167                            CRM-менеджер (Аналитик)        60000   \n",
       "168                                    Аналитик продаж        65000   \n",
       "169                    Аналитик по планированию продаж            0   \n",
       "\n",
       "     Зарплата_до Валюта   Город Дата_публикации  \\\n",
       "0         250000   руб.  Москва         28 июня   \n",
       "1         220000   руб.  Москва         26 июня   \n",
       "2              0   руб.  Москва         28 июня   \n",
       "3         210000   руб.  Москва         26 июня   \n",
       "4              0    NaN  Москва         28 июня   \n",
       "..           ...    ...     ...             ...   \n",
       "165            0    NaN  Москва           Вчера   \n",
       "166            0    NaN  Москва           Вчера   \n",
       "167            0   руб.  Москва         27 июня   \n",
       "168        80000   руб.  Москва         27 июня   \n",
       "169       120000   руб.  Москва         27 июня   \n",
       "\n",
       "                                    Ссылка_на_вакансию             Сайт  \n",
       "0                       https://hh.ru/vacancy/37713537        www.hh.ru  \n",
       "1                       https://hh.ru/vacancy/37694581        www.hh.ru  \n",
       "2                       https://hh.ru/vacancy/37715080        www.hh.ru  \n",
       "3                       https://hh.ru/vacancy/37229320        www.hh.ru  \n",
       "4                       https://hh.ru/vacancy/37595281        www.hh.ru  \n",
       "..                                                 ...              ...  \n",
       "165  https://superjob.ru/vakansii/analitik-32380682...  www.superjob.ru  \n",
       "166  https://superjob.ru/vakansii/analitik-sql-3402...  www.superjob.ru  \n",
       "167  https://superjob.ru/vakansii/crm-menedzher-339...  www.superjob.ru  \n",
       "168  https://superjob.ru/vakansii/analitik-prodazh-...  www.superjob.ru  \n",
       "169  https://superjob.ru/vakansii/analitik-po-plani...  www.superjob.ru  \n",
       "\n",
       "[170 rows x 9 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
